{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import random\n",
    "import csv\n",
    "import sqlite3 as lite\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "#train_on_gpu = False\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "    \n",
    "train_set = \"../res/train_set.tsv\"\n",
    "test_set = \"../res/test_set.tsv\"\n",
    "valid_set = \"../res/valid_set.tsv\"\n",
    "ft_vec = \"../res/crawl-300d-2M-subword.vec\"\n",
    "glove50_path = \"../res/GloveDict50.pkl\"\n",
    "\n",
    "model_path = \"../res/mod3.pth\"\n",
    "\n",
    "max_q_len = 10\n",
    "max_a_len = 100\n",
    "embedding_len = 50\n",
    "pad_char = '_'\n",
    "batch_size=32\n",
    "header_names = [\"question\",\"answer\",\"label\"]\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_vectors(fname):\n",
    "    pickle_in = open(fname,\"rb\")\n",
    "    _dict = pickle.load(pickle_in)\n",
    "    return _dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove50 = load_glove_vectors(glove50_path)\n",
    "supported_words = list(glove50.keys())\n",
    "#print(supported_words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_val = np.zeros(embedding_len)\n",
    "glove = defaultdict(lambda: default_val,glove50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetFromCSV(Dataset):\n",
    "    def __init__(self, csv_path, transform=None):\n",
    "        _dataset = pd.read_csv(csv_path, sep='\\t', header=None, names=header_names, encoding='utf8')\n",
    "        self.labels = _dataset['label']\n",
    "        self.questions = _dataset['question']\n",
    "        self.answers = _dataset['answer']\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        q = self.questions.iloc[index]\n",
    "        a = self.answers.iloc[index]\n",
    "        q = q.lower()\n",
    "        a = a.lower()\n",
    "        q = q.translate(translator)\n",
    "        a = a.translate(translator)\n",
    "        \n",
    "        tokens = set((q+\" \"+a).split(\" \"))\n",
    "        unique_vals = [x for x in tokens if x not in supported_words]      \n",
    "        \n",
    "        \n",
    "        q_list = np.zeros((max_q_len, (embedding_len+1)))\n",
    "        a_list = np.zeros((max_a_len, (embedding_len+1)))\n",
    "        \n",
    "        \n",
    "        q_words = q.split(\" \")        \n",
    "        if len(q_words) > max_q_len:\n",
    "            q_words = q_words[:max_q_len]\n",
    "        else:\n",
    "            q_words = [pad_char]*(max_q_len - len(q_words) ) + q_words\n",
    "            \n",
    "        a_words = a.split(\" \")\n",
    "        if len(a_words) > max_a_len:\n",
    "            a_words = a_words[:max_a_len]\n",
    "        else:\n",
    "            a_words = [pad_char]*(max_a_len - len(a_words) ) + a_words\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i, word in enumerate(q_words):\n",
    "            q_val = glove[word]\n",
    "            if word not in unique_vals:\n",
    "                q_val = np.append(q_val, 0)\n",
    "            else:\n",
    "                q_val = np.append(q_val, unique_vals.index(word))            \n",
    "            q_list[i] = q_val\n",
    "        \n",
    "            \n",
    "        for i, word in enumerate(a_words):\n",
    "            a_val = glove[word]\n",
    "            if word not in unique_vals:\n",
    "                a_val = np.append(a_val, 0)\n",
    "            else:\n",
    "                a_val = np.append(a_val, unique_vals.index(word))            \n",
    "            a_list[i] = a_val\n",
    "        \n",
    "        \n",
    "        x = [q_list,a_list]\n",
    "        y = self.labels.iloc[index]\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class W_RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_hidden=128, n_layers=3, drop_prob=0.2, lr=0.001):\n",
    "        super(W_RNN,self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "\n",
    "        self.lstm = nn.LSTM((embedding_len+1), n_hidden, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(n_hidden, (embedding_len+1))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network.\n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "        x = x.float()\n",
    "        r_output, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(r_output)\n",
    "         # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        #out = self.sigmoid(x)\n",
    "        return out, hidden\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "\n",
    "        return hidden\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC_OP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n",
    "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            input_size: integer, size of the input layer\n",
    "            output_size: integer, size of the output layer\n",
    "            hidden_layers: list of integers, the sizes of the hidden layers\n",
    "        \n",
    "        '''\n",
    "        super(FC_OP, self).__init__()\n",
    "        # Input to a hidden layer\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        # Add a variable number of more hidden layers\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        \n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        \n",
    "        for each in self.hidden_layers:\n",
    "            x = F.relu(each(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        #print(\"Before \",x.size())\n",
    "        x = F.sigmoid(x)\n",
    "        #print(\"After \",x.size())\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.qNet = W_RNN()\n",
    "        self.aNet = W_RNN()\n",
    "        self.fcNet = FC_OP(input_size = ((embedding_len+1)*2),\n",
    "                          output_size = 1,\n",
    "                          hidden_layers = [128,128], \n",
    "                          drop_p = 0.2)\n",
    "\n",
    "    def forward(self, questions, answers, q_hidden, a_hidden):\n",
    "        q, q_hidden = self.qNet(questions, q_hidden)\n",
    "        a, a_hidden = self.aNet(answers, a_hidden)\n",
    "        #print(q.size())\n",
    "        #print(a.size())\n",
    "        ops = torch.cat((q, a), 1)                \n",
    "        output = self.fcNet(ops)\n",
    "        return output, q_hidden, a_hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        q_hidden = self.qNet.init_hidden(batch_size)\n",
    "        a_hidden = self.aNet.init_hidden(batch_size)\n",
    "        return q_hidden, a_hidden\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model loss and optimizers here\n",
    "net = Model()\n",
    "#print(net)\n",
    "\n",
    "lr = 0.0001\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "if train_on_gpu:\n",
    "    net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_data = CustomDatasetFromCSV(test_set)    \n",
    "test_loader = torch.utils.data.DataLoader(dataset=custom_data, batch_size=32, shuffle=True)\n",
    "\n",
    "custom_data = CustomDatasetFromCSV(train_set)    \n",
    "train_loader = torch.utils.data.DataLoader(dataset=custom_data, batch_size=32, shuffle=True)\n",
    "\n",
    "custom_data = CustomDatasetFromCSV(valid_set)    \n",
    "valid_loader = torch.utils.data.DataLoader(dataset=custom_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this for both test and validation set\n",
    "def test(dataloader):\n",
    "    dataset_loss = 0\n",
    "    dataset_acc = 0\n",
    "    net.eval()\n",
    "    count = 0    \n",
    "    batches_so_far = 0\n",
    "    elements_seen = 0\n",
    "    good_case = False\n",
    "    gc_record =[]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:            \n",
    "            q = x[0]\n",
    "            a = x[1]\n",
    "            if train_on_gpu:\n",
    "                q = q.cuda()\n",
    "                a = a.cuda()\n",
    "                y = y.cuda()                \n",
    "            l = len(y)\n",
    "            if l != batch_size:\n",
    "                # last incomplete batch, skip over it.\n",
    "                continue;\n",
    "            batches_so_far += 1\n",
    "            count += 1\n",
    "            elements_seen += l\n",
    "            q_hidden, a_hidden = net.init_hidden(batch_size)            \n",
    "            output, q_hidden, a_hidden = net(questions = q, answers = a, q_hidden = q_hidden, a_hidden = a_hidden)\n",
    "            output = output.flatten()\n",
    "            loss = criterion(output, y.float())\n",
    "            interpretation = (output>0.5).float()\n",
    "            i_sum = interpretation.sum()\n",
    "            if i_sum == 0 or i_sum == l:\n",
    "                #print(\"!\", end = \"\")\n",
    "                pass\n",
    "            else:\n",
    "                good_case = True\n",
    "                gc_record.append(i_sum)\n",
    "                #print(interpretation)\n",
    "                ## print(\"True Flag \", interpretation.sum())\n",
    "            equals = interpretation == y.float()           \n",
    "            dataset_loss += loss.item()\n",
    "            dataset_acc += equals.sum()\n",
    "            \n",
    "        dataset_loss = dataset_loss/batches_so_far\n",
    "        dataset_accuracy = dataset_acc.item()/elements_seen\n",
    "        \n",
    "        if good_case:\n",
    "            print(\"!!!GOODCASE!!!\\n\",gc_record,\"\\n\")\n",
    "            gc_record = []\n",
    "            good_case = False\n",
    "        \n",
    "    return dataset_loss, dataset_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_this(d1, d2, name):\n",
    "    plt.figure(name)\n",
    "    lists1 = d1.items() # sorted by key, return a list of tuples\n",
    "    lists2 = d2.items() # sorted by key, return a list of tuples\n",
    "    x1, y1 = zip(*lists1) # unpack a list of pairs into two tuples\n",
    "    x2, y2 = zip(*lists2) # unpack a list of pairs into two tuples\n",
    "    plt.plot(x1, y1, label = \"train\")\n",
    "    plt.plot(x2, y2, label = \"valid\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtl = {}\n",
    "dta = {}   \n",
    "dvl = {}\n",
    "dva = {}\n",
    "\n",
    "lowest_loss = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch=1, print_every=1, clip = 5):\n",
    "    net.train()\n",
    "    train_loss = 0;\n",
    "    train_acc = 0;\n",
    "    valid_loss = 0;\n",
    "    valid_acc = 0;\n",
    "    count = 0    \n",
    "    \n",
    "    dtl = {}\n",
    "    dta = {}   \n",
    "    dvl = {}\n",
    "    dva = {}\n",
    "    \n",
    "    interrupted = False\n",
    "\n",
    "    lowest_loss = np.inf\n",
    "    \n",
    "    for e in range(epoch):\n",
    "        \n",
    "        batches_so_far = 0\n",
    "        elements_seen = 0\n",
    "        for x, y in train_loader:            \n",
    "            q = x[0]\n",
    "            a = x[1]\n",
    "            if train_on_gpu:\n",
    "                q = q.cuda()\n",
    "                a = a.cuda()\n",
    "                y = y.cuda()                \n",
    "            l = len(y)      \n",
    "            if interrupted:\n",
    "                interrupted = False\n",
    "                print(\"Continue as usual again\")\n",
    "            \n",
    "            if l != batch_size:\n",
    "                print(\"Abrupt batch size for training, l = \", l)\n",
    "                print(\"epoch \", e)\n",
    "                print(\"count \", count)\n",
    "                print(\"batches_so_far \", batches_so_far)\n",
    "                print(\"elements_seen \", elements_seen)\n",
    "                interrupted = True\n",
    "                \n",
    "                # last incomplete batch, skip over it.\n",
    "                continue;\n",
    "            elements_seen += l # not one, but l\n",
    "            batches_so_far +=1\n",
    "            count += 1            \n",
    "            net.zero_grad()\n",
    "            q_hidden, a_hidden = net.init_hidden(batch_size)            \n",
    "            output, q_hidden, a_hidden = net(questions = q, answers = a, q_hidden = q_hidden, a_hidden = a_hidden)\n",
    "            \n",
    "            #output = output.flatten()\n",
    "            #print(\"\\n\\n\\noutput \",output.flatten())\n",
    "            #print(\"\\n\\n\\noutput \",output.size())\n",
    "            #print(\"\\ny.float() \",y.size() )\n",
    "            y = y.view(batch_size, -1)\n",
    "            #print(\"\\ny.float() \",y.size() )\n",
    "            #print(\"\\nmodel path \",model_path )\n",
    "            \n",
    "            loss = criterion(output, y.float())\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "            interpretation = (output>0.5).float()\n",
    "            equals = interpretation == y.float()            \n",
    "            train_loss += loss.item()\n",
    "            train_acc += equals.sum()\n",
    "            #print(\"\\ninterpretation \",interpretation)\n",
    "            #print(\"\\ny.float() \",y.float() )\n",
    "            #print(\"\\ntrain ac\",train_acc)\n",
    "            #print(\"\\elements_seen \",elements_seen)\n",
    "            #print(\"\\equals \",equals)\n",
    "            #print(\"\\sum \",equals.sum())\n",
    "            \n",
    "            if count%print_every == 0:\n",
    "                # why counts are batch size and not int\n",
    "                train_loss = train_loss/batches_so_far\n",
    "                #print(\"\\n1 train ac\",train_acc)\n",
    "                train_accuracy = train_acc.item()/elements_seen                \n",
    "                #print(\"\\n2 train ac\",train_acc)\n",
    "                \n",
    "                # to save some time at initial training\n",
    "                # calculate validation only after 1000 batches\n",
    "                #if count > 200:\n",
    "                valid_loss, valid_accuracy = test(valid_loader)\n",
    "                #else:\n",
    "                #valid_loss = train_loss\n",
    "                #valid_accuracy = train_accuracy\n",
    "                    \n",
    "                clear_output(wait=True)\n",
    "                print(\"Train Loss \", train_loss, \"\\tTrain Acc \", train_accuracy, \"\\nValid Loss\", valid_loss, \"\\tValid Acc\", valid_accuracy)\n",
    "                if  valid_loss < lowest_loss:\n",
    "                    lowest_loss = valid_loss\n",
    "                    \n",
    "                    torch.save(net.state_dict(),model_path)                \n",
    "                net.train()                    \n",
    "                dtl[count]= train_loss\n",
    "                dvl[count]= valid_loss\n",
    "                dta[count]= train_accuracy\n",
    "                dva[count]= valid_accuracy\n",
    "                plot_this(dtl, dvl, \"Loss\")\n",
    "                plot_this(dta, dva, \"Acc\")\n",
    "                \n",
    "                batches_so_far = 0\n",
    "                elements_seen = 0\n",
    "                train_loss = 0;\n",
    "                train_acc = 0;\n",
    "                valid_loss = 0;\n",
    "                valid_acc = 0;\n",
    "                \n",
    "                #if count == 5: break\n",
    "                \n",
    "            #break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss  0.6841041797399521 \tTrain Acc  0.56125 \n",
      "Valid Loss 0.6852122085695048 \tValid Acc 0.5570133587786259\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(epoch = 10, print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple load\n",
    "state_dict_1 = torch.load(model_path)\n",
    "\n",
    "# simple load into model\n",
    "net.load_state_dict(state_dict_1)\n",
    "if train_on_gpu:\n",
    "    net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = test(test_loader)\n",
    "\n",
    "#clear_output(wait=True)\n",
    "print(\"test_loss \", test_loss, \"\\ttest_accuracy \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
